{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c25882",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import torch\n",
    "from transformers import VisionEncoderDecoderModel, TrOCRProcessor, Trainer, TrainingArguments, TrainerCallback\n",
    "import evaluate\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec183ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.2\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./spanish_ocr_model\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir=\"./logs\",\n",
    "    save_total_limit=2,\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=30,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"cer\",\n",
    "    greater_is_better=False,\n",
    "    report_to=\"none\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44437d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpanishOCRDataset(Dataset):\n",
    "    def __init__(self, dataframe, images_dir, processor, max_target_length=128):\n",
    "        self.data = dataframe.reset_index(drop=True)\n",
    "        self.images_dir = images_dir\n",
    "        self.processor = processor\n",
    "        self.max_target_length = max_target_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        img_path = os.path.join(self.images_dir, row['image_path'])\n",
    "        text = row['text']\n",
    "\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        pixel_values = self.processor(images=image, return_tensors=\"pt\").pixel_values.squeeze(0)\n",
    "        labels = self.processor.tokenizer(\n",
    "            text,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_target_length,\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\"\n",
    "        ).input_ids.squeeze(0)\n",
    "        labels[labels == self.processor.tokenizer.pad_token_id] = -100\n",
    "\n",
    "        return {\n",
    "            \"pixel_values\": pixel_values,\n",
    "            \"labels\": labels,\n",
    "        }\n",
    "    \n",
    "class TQDMProgressBar(TrainerCallback):\n",
    "    def __init__(self):\n",
    "        self.progress_bar = None\n",
    "\n",
    "    def on_train_begin(self, args, state, control, **kwargs):\n",
    "        self.progress_bar = tqdm(total=state.max_steps, desc=\"Training Progress\", dynamic_ncols=True)\n",
    "\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        if self.progress_bar is not None and logs is not None:\n",
    "            loss = logs.get('loss', None)\n",
    "            if loss is not None:\n",
    "                desc = f\"Epoch {int(state.epoch)} | Step {state.global_step} | Loss {loss:.4f}\"\n",
    "            else:\n",
    "                desc = f\"Epoch {int(state.epoch)} | Step {state.global_step}\"\n",
    "\n",
    "            if 'eval_cer' in logs:\n",
    "                desc += f\" | CER {logs['eval_cer']:.4f}\"\n",
    "            if 'eval_wer' in logs:\n",
    "                desc += f\" | WER {logs['eval_wer']:.4f}\"\n",
    "\n",
    "            self.progress_bar.set_description(desc)\n",
    "\n",
    "    def on_step_end(self, args, state, control, **kwargs):\n",
    "        if self.progress_bar is not None:\n",
    "            self.progress_bar.update(1)\n",
    "\n",
    "    def on_train_end(self, args, state, control, **kwargs):\n",
    "        if self.progress_bar is not None:\n",
    "            self.progress_bar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6595ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    processor = TrOCRProcessor.from_pretrained(\"microsoft/trocr-base-printed\")\n",
    "    model = VisionEncoderDecoderModel.from_pretrained(\"microsoft/trocr-base-printed\")\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "    elif torch.backends.mps.is_available():\n",
    "        device = torch.device(\"mps\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        \n",
    "    model = model.to(device)\n",
    "    model.config.decoder_start_token_id = processor.tokenizer.cls_token_id\n",
    "    model.config.pad_token_id = processor.tokenizer.pad_token_id\n",
    "    print(\"Model built\")\n",
    "    return processor, model\n",
    "\n",
    "def build_datasets(processor, test_size=0.1):\n",
    "    df = pd.read_csv(\"data/spanish_data.csv\")\n",
    "    train_df, val_df = train_test_split(df, test_size=test_size, random_state=42)\n",
    "\n",
    "    train_dataset = SpanishOCRDataset(train_df, \"data/images/\", processor)\n",
    "    val_dataset = SpanishOCRDataset(val_df, \"data/images/\", processor)\n",
    "\n",
    "    print(\"Dataset built\")\n",
    "\n",
    "    return train_dataset, val_dataset\n",
    "\n",
    "def build_compute_metrics(processor):\n",
    "    def compute_metrics(pred):\n",
    "        pred_ids = pred.predictions\n",
    "        label_ids = pred.label_ids\n",
    "\n",
    "        if isinstance(pred_ids, tuple):\n",
    "            pred_ids = pred_ids[0]\n",
    "        pred_ids = torch.tensor(pred_ids)\n",
    "        pred_ids = torch.argmax(pred_ids, dim=-1)\n",
    "\n",
    "        label_ids = torch.tensor(label_ids)\n",
    "        label_ids[label_ids == -100] = processor.tokenizer.pad_token_id\n",
    "\n",
    "        pred_str = processor.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "        label_str = processor.batch_decode(label_ids, skip_special_tokens=True)\n",
    "\n",
    "        cer_metric = evaluate.load(\"cer\")\n",
    "        wer_metric = evaluate.load(\"wer\")\n",
    "\n",
    "        cer = cer_metric.compute(predictions=pred_str, references=label_str)\n",
    "        wer = wer_metric.compute(predictions=pred_str, references=label_str)\n",
    "\n",
    "        return {\"cer\": cer, \"wer\": wer}\n",
    "\n",
    "    return compute_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf4c8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor, model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4b380b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset = build_datasets(processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2bc29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_metrics = build_compute_metrics(processor)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[TQDMProgressBar()],\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f6c003",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"./spanish_ocr_model\")\n",
    "processor.save_pretrained(\"./spanish_ocr_model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
